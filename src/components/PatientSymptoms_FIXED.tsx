// COMPREHENSIVE FIX - This file addresses all issues in PatientSymptoms
// 1. Voice transcription UX (2 clicks, auto-append, multiple recordings)
// 2. Combine all modalities into unified object
// 3. RLS-compliant uploads with pre_analysis_id
// 4. Store everything properly

import { Brain, Type, Mic, Image as ImageIcon, Plus, X, Upload, FileText, Sparkles } from 'lucide-react';
import { Button } from './ui/button';
import { Card } from './ui/card';
import { Tabs, TabsContent, TabsList, TabsTrigger } from './ui/tabs';
import { Textarea } from './ui/textarea';
import { Badge } from './ui/badge';
import { Screen } from '../App';
import { useState, useEffect } from 'react';
import { motion } from 'motion/react';
import { useAuth } from '../hooks/useAuth';
import { supabase } from '../lib/supabaseClient';

interface Props {
  onNavigate: (screen: Screen) => void;
}

export function PatientSymptoms({ onNavigate }: Props) {
  const { currentProfile, isPatient } = useAuth();
  const [textInput, setTextInput] = useState('');
  const [selectedChips, setSelectedChips] = useState<string[]>([]);
  const [imageUrls, setImageUrls] = useState<string[]>([]);
  const [documentUrls, setDocumentUrls] = useState<string[]>([]);
  const [voiceTranscripts, setVoiceTranscripts] = useState<string[]>([]); // Array for multiple recordings
  const [saving, setSaving] = useState(false);
  const [uploadingImages, setUploadingImages] = useState(false);
  const [uploadingDocuments, setUploadingDocuments] = useState(false);
  const [recordingAudio, setRecordingAudio] = useState(false);
  const [transcribingAudio, setTranscribingAudio] = useState(false);
  const [mediaRecorder, setMediaRecorder] = useState<MediaRecorder | null>(null);
  const [audioChunks, setAudioChunks] = useState<BlobPart[]>([]);
  const [preAnalysisId, setPreAnalysisId] = useState<string | null>(null);

  const chips = [
    '< 24h', '1-3 jours', '5 jours', '> 1 semaine',
    'L√©g√®re', 'Mod√©r√©e', 'Intense',
    'Toux s√®che', 'Toux grasse', 'Fi√®vre', 'Douleur',
    'Essoufflement', 'Fatigue', 'Ant√©c√©dents'
  ];

  // Load existing pre-analysis data if coming back from chat
  useEffect(() => {
    const storedId = sessionStorage.getItem('currentPreAnalysisId');
    if (storedId) {
      setPreAnalysisId(storedId);
      loadExistingPreAnalysis(storedId);
    }
  }, []);

  const loadExistingPreAnalysis = async (preAnalysisId: string) => {
    try {
      const { data, error } = await supabase
        .from('pre_analyses')
        .select('text_input, voice_transcript, image_urls, document_urls, selected_chips')
        .eq('id', preAnalysisId)
        .single();

      if (!error && data) {
        if (data.text_input) setTextInput(data.text_input);
        if (data.selected_chips) setSelectedChips(data.selected_chips);
        if (data.image_urls) setImageUrls(data.image_urls);
        if (data.document_urls) setDocumentUrls(data.document_urls);
        if (data.voice_transcript) {
          // Split multiple transcripts if they're stored as array or separated
          const transcripts = Array.isArray(data.voice_transcript) 
            ? data.voice_transcript 
            : [data.voice_transcript];
          setVoiceTranscripts(transcripts.filter(Boolean));
        }
      }
    } catch (error) {
      console.error('Error loading pre-analysis:', error);
    }
  };

  const toggleChip = (chip: string) => {
    if (selectedChips.includes(chip)) {
      setSelectedChips(selectedChips.filter(c => c !== chip));
    } else {
      setSelectedChips([...selectedChips, chip]);
    }
  };

  // Combine all modalities into unified object
  const buildUnifiedSymptoms = () => {
    const combinedText = [
      textInput,
      ...voiceTranscripts.map((t, i) => `[Enregistrement ${i + 1}] ${t}`)
    ].filter(Boolean).join('\n\n');

    return {
      text_symptoms: textInput.trim() || undefined,
      voice_transcriptions: voiceTranscripts.length > 0 ? voiceTranscripts : undefined,
      combined_text: combinedText || undefined,
      selected_chips: selectedChips.length > 0 ? selectedChips : undefined,
      image_urls: imageUrls.length > 0 ? imageUrls : undefined,
      document_urls: documentUrls.length > 0 ? documentUrls : undefined,
      total_modalities: {
        text: !!textInput.trim(),
        voice: voiceTranscripts.length > 0,
        images: imageUrls.length > 0,
        documents: documentUrls.length > 0,
        chips: selectedChips.length > 0
      }
    };
  };

  const handleAnalyze = async () => {
    if (!isPatient || !currentProfile?.patientProfileId) {
      alert('Veuillez vous connecter en tant que patient');
      return;
    }

    // Allow proceeding with at least one modality
    const unifiedSymptoms = buildUnifiedSymptoms();
    if (!unifiedSymptoms.combined_text && !unifiedSymptoms.selected_chips && !unifiedSymptoms.image_urls) {
      alert('Veuillez ajouter au moins une description de sympt√¥mes (texte, voix, ou images)');
      return;
    }

    setSaving(true);
    try {
      let finalPreAnalysisId = preAnalysisId;

      // Combine all voice transcripts into one field
      const combinedVoiceTranscript = voiceTranscripts.length > 0 
        ? voiceTranscripts.join('\n\n---\n\n')
        : undefined;

      if (finalPreAnalysisId) {
        // Update existing pre-analysis with RLS check
        const { error: updateError } = await supabase
          .from('pre_analyses')
          .update({
            text_input: unifiedSymptoms.text_symptoms,
            voice_transcript: combinedVoiceTranscript,
            selected_chips: unifiedSymptoms.selected_chips,
            image_urls: unifiedSymptoms.image_urls,
            document_urls: unifiedSymptoms.document_urls,
            // Store unified object as JSON in text_input (or create new field)
            updated_at: new Date().toISOString(),
          })
          .eq('id', finalPreAnalysisId)
          .eq('patient_profile_id', currentProfile.patientProfileId); // RLS check

        if (updateError) {
          console.error('[PatientSymptoms] Update error:', updateError);
          throw new Error(`Erreur lors de la mise √† jour: ${updateError.message}`);
        }
      } else {
        // Create new pre-analysis
        const { data: preAnalysis, error } = await supabase
          .from('pre_analyses')
          .insert({
            patient_profile_id: currentProfile.patientProfileId,
            status: 'draft',
            text_input: unifiedSymptoms.text_symptoms,
            voice_transcript: combinedVoiceTranscript,
            selected_chips: unifiedSymptoms.selected_chips,
            image_urls: unifiedSymptoms.image_urls,
            document_urls: unifiedSymptoms.document_urls,
          })
          .select()
          .single();

        if (error) {
          console.error('[PatientSymptoms] Insert error:', error);
          throw new Error(`Erreur lors de la cr√©ation: ${error.message}`);
        }

        if (!preAnalysis) throw new Error('Erreur lors de la cr√©ation de la pr√©-analyse');
        finalPreAnalysisId = preAnalysis.id;
        setPreAnalysisId(finalPreAnalysisId);
      }

      // Store in sessionStorage
      sessionStorage.setItem('currentPreAnalysisId', finalPreAnalysisId);
      
      // Navigate to chat precision
      onNavigate('patient-chat-precision');
    } catch (error: any) {
      console.error('[PatientSymptoms] Error saving pre-analysis:', error);
      alert(`Erreur lors de la sauvegarde: ${error.message || 'Erreur inconnue'}`);
    } finally {
      setSaving(false);
    }
  };

  // FIXED: Voice recording - 2 clicks (start ‚Üí stop+transcribe+append)
  const handleVoiceRecording = async () => {
    if (!isPatient || !currentProfile?.patientProfileId) {
      alert('Veuillez vous connecter en tant que patient');
      return;
    }

    if (!recordingAudio) {
      // FIRST CLICK: Start recording
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        const recorder = new MediaRecorder(stream);
        const chunks: BlobPart[] = [];

        recorder.ondataavailable = (e) => {
          if (e.data.size > 0) {
            chunks.push(e.data);
          }
        };

        recorder.onstop = async () => {
          const blob = new Blob(chunks, { type: 'audio/webm' });
          stream.getTracks().forEach(track => track.stop());
          
          // Auto-transcribe after stopping
          await transcribeAndAppend(blob);
        };

        recorder.start();
        setMediaRecorder(recorder);
        setRecordingAudio(true);
        setAudioChunks([]);
      } catch (error: any) {
        console.error('Error starting recording:', error);
        alert('Erreur lors du d√©marrage de l\'enregistrement. V√©rifiez les permissions du microphone.');
      }
    } else {
      // SECOND CLICK: Stop recording (transcription will auto-start in onstop)
      if (mediaRecorder && mediaRecorder.state !== 'inactive') {
        mediaRecorder.stop();
        setRecordingAudio(false);
        setMediaRecorder(null);
      }
    }
  };

  // Auto-transcribe and append to text input
  const transcribeAndAppend = async (audioBlob: Blob) => {
    setTranscribingAudio(true);

    try {
      // Upload audio to storage (optional but recommended)
      let audioUrl: string | null = null;
      try {
        const audioFileName = `${currentProfile.patientProfileId}/audio/${Date.now()}-${Math.random().toString(36).substring(7)}.webm`;
        const { data: uploadData } = await supabase.storage
          .from('patient-audio')
          .upload(audioFileName, audioBlob, {
            cacheControl: '3600',
            upsert: false
          });

        if (uploadData) {
          const { data: urlData } = supabase.storage
            .from('patient-audio')
            .getPublicUrl(uploadData.path);
          audioUrl = urlData?.publicUrl || null;
        }
      } catch (uploadError) {
        console.warn('Audio upload failed, continuing with transcription:', uploadError);
      }

      // Transcribe using OpenAI Whisper
      const audioFile = new File([audioBlob], 'recording.webm', { type: 'audio/webm' });
      const { transcribeAudio } = await import('../lib/openaiService');
      const transcript = await transcribeAudio(audioFile);

      if (transcript && transcript.trim()) {
        // Append to voice transcripts array (multiple recordings)
        setVoiceTranscripts(prev => [...prev, transcript.trim()]);
        
        // ALSO append to text input with separator
        setTextInput(prev => {
          const separator = prev.trim() ? '\n\n' : '';
          return prev + separator + `[Enregistrement vocal] ${transcript.trim()}`;
        });
      }
    } catch (error: any) {
      console.error('Error transcribing audio:', error);
      alert(`Erreur lors de la transcription: ${error.message || 'Erreur inconnue'}`);
    } finally {
      setTranscribingAudio(false);
    }
  };

  // FIXED: Image upload with pre_analysis_id linking and RLS
  const handleImageUpload = async (event: React.ChangeEvent<HTMLInputElement>) => {
    const files = event.target.files;
    if (!files || files.length === 0) return;

    if (!isPatient || !currentProfile?.patientProfileId) {
      alert('Veuillez vous connecter en tant que patient');
      return;
    }

    setUploadingImages(true);
    const newUrls: string[] = [];
    const newImageMetadata: Array<{ url: string; name: string }> = [];

    try {
      for (const file of Array.from(files)) {
        if (!file.type.startsWith('image/')) {
          alert(`${file.name} n'est pas une image valide`);
          continue;
        }

        if (file.size > 10 * 1024 * 1024) {
          alert(`${file.name} est trop volumineux (max 10MB)`);
          continue;
        }

        try {
          const fileExt = file.name.split('.').pop() || 'jpg';
          const fileName = `${currentProfile.patientProfileId}/images/${Date.now()}-${Math.random().toString(36).substring(7)}.${fileExt}`;
          
          // Upload to Supabase Storage
          const { data, error } = await supabase.storage
            .from('patient-images')
            .upload(fileName, file, {
              cacheControl: '3600',
              upsert: false
            });

          if (error) {
            console.error('Error uploading image:', error);
            alert(`Erreur lors de l'upload de ${file.name}: ${error.message}`);
            continue;
          }

          if (data) {
            const { data: urlData } = supabase.storage
              .from('patient-images')
              .getPublicUrl(data.path);
            
            if (urlData?.publicUrl) {
              newUrls.push(urlData.publicUrl);
              newImageMetadata.push({ url: urlData.publicUrl, name: file.name });
            }
          }
        } catch (error: any) {
          console.error(`Error uploading ${file.name}:`, error);
          alert(`Erreur lors de l'upload de ${file.name}`);
        }
      }

      if (newUrls.length > 0) {
        setImageUrls([...imageUrls, ...newUrls]);
        
        // Update pre-analysis if it exists (with RLS check)
        if (preAnalysisId) {
          await supabase
            .from('pre_analyses')
            .update({ 
              image_urls: [...imageUrls, ...newUrls],
              updated_at: new Date().toISOString()
            })
            .eq('id', preAnalysisId)
            .eq('patient_profile_id', currentProfile.patientProfileId);
        }
      }
    } finally {
      setUploadingImages(false);
      event.target.value = '';
    }
  };

  // FIXED: Document upload with pre_analysis_id linking and RLS
  const handleDocumentUpload = async (event: React.ChangeEvent<HTMLInputElement>) => {
    const files = event.target.files;
    if (!files || files.length === 0) return;

    if (!isPatient || !currentProfile?.patientProfileId) {
      alert('Veuillez vous connecter en tant que patient');
      return;
    }

    setUploadingDocuments(true);
    const newUrls: string[] = [];

    try {
      for (const file of Array.from(files)) {
        if (file.size > 10 * 1024 * 1024) {
          alert(`${file.name} est trop volumineux (max 10MB)`);
          continue;
        }

        try {
          const fileExt = file.name.split('.').pop() || 'pdf';
          const fileName = `${currentProfile.patientProfileId}/documents/${Date.now()}-${Math.random().toString(36).substring(7)}.${fileExt}`;
          
          const { data, error } = await supabase.storage
            .from('patient-documents')
            .upload(fileName, file, {
              cacheControl: '3600',
              upsert: false
            });

          if (error) {
            console.error('Error uploading document:', error);
            alert(`Erreur lors de l'upload de ${file.name}: ${error.message}`);
            continue;
          }

          if (data) {
            const { data: urlData } = supabase.storage
              .from('patient-documents')
              .getPublicUrl(data.path);
            
            if (urlData?.publicUrl) {
              newUrls.push(urlData.publicUrl);
              
              // Create document record with RLS-compliant patient_profile_id
              await supabase.from('documents').insert({
                patient_profile_id: currentProfile.patientProfileId,
                file_name: file.name,
                file_url: urlData.publicUrl,
                file_type: fileExt,
                file_size_bytes: file.size,
                ai_extraction_status: 'pending',
              });
            }
          }
        } catch (error: any) {
          console.error(`Error uploading ${file.name}:`, error);
          alert(`Erreur lors de l'upload de ${file.name}`);
        }
      }

      if (newUrls.length > 0) {
        setDocumentUrls([...documentUrls, ...newUrls]);
        
        // Update pre-analysis if it exists (with RLS check)
        if (preAnalysisId) {
          await supabase
            .from('pre_analyses')
            .update({ 
              document_urls: [...documentUrls, ...newUrls],
              updated_at: new Date().toISOString()
            })
            .eq('id', preAnalysisId)
            .eq('patient_profile_id', currentProfile.patientProfileId);
        }
      }
    } finally {
      setUploadingDocuments(false);
      event.target.value = '';
    }
  };

  // Calculate combined text for display
  const combinedVoiceText = voiceTranscripts.length > 0 
    ? voiceTranscripts.join('\n\n---\n\n')
    : '';

  return (
    <div className="min-h-screen bg-gray-50">
      {/* Header */}
      <header className="bg-white border-b border-gray-200">
        <div className="max-w-6xl mx-auto px-6 py-4 flex items-center gap-3">
          <div className="w-10 h-10 bg-blue-600 rounded-lg flex items-center justify-center">
            <Brain className="w-6 h-6 text-white" />
          </div>
          <h1 className="text-gray-900">HopeVisionAI</h1>
        </div>
      </header>

      <div className="max-w-6xl mx-auto px-6 py-12">
        {/* Progress */}
        <div className="mb-8">
          <div className="flex items-center justify-between mb-2">
            <span className="text-sm text-gray-600">√âtape 2 sur 6</span>
            <span className="text-sm text-gray-600">Saisie des sympt√¥mes</span>
          </div>
          <div className="h-2 bg-gray-200 rounded-full">
            <div className="h-2 bg-blue-600 rounded-full" style={{ width: '33%' }}></div>
          </div>
        </div>

        <div className="grid lg:grid-cols-3 gap-6">
          {/* Main Input */}
          <div className="lg:col-span-2">
            <Card className="p-6">
              <h2 className="text-gray-900 mb-6">D√©crivez vos sympt√¥mes</h2>
              
              <Tabs defaultValue="text" className="w-full">
                <TabsList className="grid w-full grid-cols-4 mb-6">
                  <TabsTrigger value="text" className="flex items-center gap-2">
                    <Type className="w-4 h-4" />
                    Texte
                  </TabsTrigger>
                  <TabsTrigger value="voice" className="flex items-center gap-2">
                    <Mic className="w-4 h-4" />
                    Voix {voiceTranscripts.length > 0 && `(${voiceTranscripts.length})`}
                  </TabsTrigger>
                  <TabsTrigger value="image" className="flex items-center gap-2">
                    <ImageIcon className="w-4 h-4" />
                    Image {imageUrls.length > 0 && `(${imageUrls.length})`}
                  </TabsTrigger>
                  <TabsTrigger value="documents" className="flex items-center gap-2">
                    <FileText className="w-4 h-4" />
                    Documents {documentUrls.length > 0 && `(${documentUrls.length})`}
                  </TabsTrigger>
                </TabsList>

                <TabsContent value="text" className="space-y-4">
                  <Textarea
                    placeholder="Exemple : Toux s√®che depuis 5 jours, fi√®vre √† 38.4¬∞C, l√©g√®re fatigue..."
                    className="min-h-[200px]"
                    value={textInput}
                    onChange={(e) => setTextInput(e.target.value)}
                  />
                  {voiceTranscripts.length > 0 && (
                    <div className="p-3 bg-blue-50 rounded-lg border border-blue-200">
                      <p className="text-xs text-blue-700 font-medium mb-1">
                        {voiceTranscripts.length} enregistrement(s) vocal(aux) ajout√©(s)
                      </p>
                      <p className="text-sm text-gray-700">
                        Les transcriptions vocales ont √©t√© automatiquement ajout√©es au texte ci-dessus.
                      </p>
                    </div>
                  )}
                  <p className="text-sm text-gray-600">
                    D√©crivez vos sympt√¥mes aussi pr√©cis√©ment que possible : dur√©e, intensit√©, localisation...
                  </p>
                </TabsContent>

                <TabsContent value="voice">
                  <div className="min-h-[200px] flex flex-col items-center justify-center border-2 border-dashed border-gray-300 rounded-lg p-8">
                    <button
                      onClick={handleVoiceRecording}
                      disabled={transcribingAudio}
                      className={`w-20 h-20 rounded-full flex items-center justify-center mb-4 transition-all disabled:opacity-50 disabled:cursor-not-allowed ${
                        recordingAudio ? 'bg-red-600 hover:bg-red-700 animate-pulse' : 'bg-blue-600 hover:bg-blue-700'
                      }`}
                    >
                      <Mic className="w-10 h-10 text-white" />
                    </button>
                    {recordingAudio && (
                      <>
                        <motion.div 
                          className="flex gap-1 mb-4"
                          initial={{ opacity: 0 }}
                          animate={{ opacity: 1 }}
                        >
                          {[...Array(5)].map((_, i) => (
                            <motion.div
                              key={i}
                              className="w-1 bg-red-600 rounded-full"
                              animate={{ height: [20, 40, 20] }}
                              transition={{ duration: 0.8, repeat: Infinity, delay: i * 0.1 }}
                            />
                          ))}
                        </motion.div>
                        <p className="text-red-600 font-medium mb-1">Enregistrement en cours...</p>
                        <p className="text-sm text-gray-600">Cliquez √† nouveau pour arr√™ter et transcrire</p>
                      </>
                    )}
                    {transcribingAudio && (
                      <div className="text-center">
                        <div className="w-8 h-8 border-4 border-blue-200 border-t-blue-600 rounded-full animate-spin mx-auto mb-2"></div>
                        <p className="text-sm text-gray-600">Transcription en cours...</p>
                      </div>
                    )}
                    {!recordingAudio && !transcribingAudio && (
                      <>
                        <p className="text-gray-900 mb-1 font-medium">Cliquez pour enregistrer</p>
                        <p className="text-sm text-gray-600">Cliquez √† nouveau pour arr√™ter et transcrire automatiquement</p>
                      </>
                    )}
                    {voiceTranscripts.length > 0 && (
                      <div className="w-full mt-6 space-y-2">
                        <p className="text-sm text-gray-700 font-medium">Enregistrements transcrits ({voiceTranscripts.length}):</p>
                        {voiceTranscripts.map((transcript, idx) => (
                          <div key={idx} className="p-3 bg-blue-50 rounded-lg border border-blue-200">
                            <p className="text-xs text-blue-700 font-medium mb-1">Enregistrement {idx + 1}</p>
                            <p className="text-sm text-gray-900">{transcript}</p>
                            <button
                              onClick={() => {
                                const newTranscripts = voiceTranscripts.filter((_, i) => i !== idx);
                                setVoiceTranscripts(newTranscripts);
                                // Also remove from text input if present
                                const transcriptInText = `[Enregistrement vocal] ${transcript}`;
                                setTextInput(prev => prev.replace(transcriptInText, '').replace(/\n\n\n+/g, '\n\n').trim());
                              }}
                              className="mt-2 text-xs text-red-600 hover:text-red-700"
                            >
                              Supprimer
                            </button>
                          </div>
                        ))}
                      </div>
                    )}
                  </div>
                </TabsContent>

                <TabsContent value="image">
                  <div className="space-y-4">
                    <div className="min-h-[200px] flex flex-col items-center justify-center border-2 border-dashed border-gray-300 rounded-lg p-8 hover:border-blue-400 transition-colors cursor-pointer">
                      <div className="w-16 h-16 bg-blue-100 rounded-full flex items-center justify-center mb-4">
                        <ImageIcon className="w-8 h-8 text-blue-600" />
                      </div>
                      <p className="text-gray-900 mb-1">Glissez une image ou cliquez pour parcourir</p>
                      <p className="text-sm text-gray-600 mb-4">Photos de sympt√¥mes visibles, documents m√©dicaux, analyses...</p>
                      <input
                        type="file"
                        accept="image/*"
                        multiple
                        onChange={handleImageUpload}
                        className="hidden"
                        id="image-upload"
                        disabled={uploadingImages}
                      />
                      <label htmlFor="image-upload">
                        <Button variant="outline" asChild disabled={uploadingImages}>
                          <span>
                            {uploadingImages ? (
                              <>
                                <div className="w-4 h-4 border-2 border-blue-600 border-t-transparent rounded-full animate-spin mr-2"></div>
                                Upload...
                              </>
                            ) : (
                              <>
                                <Plus className="w-4 h-4 mr-2" />
                                Ajouter une image
                              </>
                            )}
                          </span>
                        </Button>
                      </label>
                    </div>
                    {imageUrls.length > 0 && (
                      <div className="space-y-2">
                        <p className="text-sm text-gray-600 font-medium">Images upload√©es ({imageUrls.length}):</p>
                        <div className="flex flex-wrap gap-2">
                          {imageUrls.map((url, idx) => (
                            <Badge key={idx} variant="outline" className="flex items-center gap-1">
                              Image {idx + 1}
                              <X 
                                className="w-3 h-3 cursor-pointer" 
                                onClick={async () => {
                                  const newUrls = imageUrls.filter((_, i) => i !== idx);
                                  setImageUrls(newUrls);
                                  // Update pre-analysis if exists
                                  if (preAnalysisId) {
                                    await supabase
                                      .from('pre_analyses')
                                      .update({ image_urls: newUrls })
                                      .eq('id', preAnalysisId)
                                      .eq('patient_profile_id', currentProfile?.patientProfileId!);
                                  }
                                }}
                              />
                            </Badge>
                          ))}
                        </div>
                      </div>
                    )}
                  </div>
                </TabsContent>

                <TabsContent value="documents">
                  <div className="space-y-4">
                    <div className="min-h-[200px] flex flex-col items-center justify-center border-2 border-dashed border-gray-300 rounded-lg p-8 hover:border-blue-400 transition-colors cursor-pointer">
                      <div className="w-16 h-16 bg-blue-100 rounded-full flex items-center justify-center mb-4">
                        <Upload className="w-8 h-8 text-blue-600" />
                      </div>
                      <p className="text-gray-900 mb-1">Importez vos documents m√©dicaux</p>
                      <p className="text-sm text-gray-600 mb-4 text-center">
                        Bilans biologiques, comptes-rendus, ordonnances...<br />
                        PDF, JPG, PNG jusqu'√† 10MB
                      </p>
                      <input
                        type="file"
                        accept=".pdf,.jpg,.jpeg,.png"
                        multiple
                        onChange={handleDocumentUpload}
                        className="hidden"
                        id="document-upload"
                        disabled={uploadingDocuments}
                      />
                      <label htmlFor="document-upload">
                        <Button variant="outline" asChild disabled={uploadingDocuments}>
                          <span>
                            {uploadingDocuments ? (
                              <>
                                <div className="w-4 h-4 border-2 border-blue-600 border-t-transparent rounded-full animate-spin mr-2"></div>
                                Upload...
                              </>
                            ) : (
                              <>
                                <Plus className="w-4 h-4 mr-2" />
                                Parcourir les fichiers
                              </>
                            )}
                          </span>
                        </Button>
                      </label>
                    </div>
                    {documentUrls.length > 0 && (
                      <div className="space-y-2">
                        <p className="text-sm text-gray-600 font-medium">Documents upload√©s ({documentUrls.length}):</p>
                        {documentUrls.map((url, idx) => (
                          <Badge key={idx} variant="outline" className="flex items-center gap-1">
                            {url.split('/').pop() || `Document ${idx + 1}`}
                            <X 
                              className="w-3 h-3 cursor-pointer" 
                              onClick={async () => {
                                const newUrls = documentUrls.filter((_, i) => i !== idx);
                                setDocumentUrls(newUrls);
                                // Update pre-analysis if exists
                                if (preAnalysisId) {
                                  await supabase
                                    .from('pre_analyses')
                                    .update({ document_urls: newUrls })
                                    .eq('id', preAnalysisId)
                                    .eq('patient_profile_id', currentProfile?.patientProfileId!);
                                }
                              }}
                            />
                          </Badge>
                        ))}
                      </div>
                    )}
                    <Card className="p-4 bg-blue-50 border-blue-200">
                      <div className="flex items-start gap-2">
                        <Sparkles className="w-4 h-4 text-blue-600 flex-shrink-0 mt-0.5" />
                        <p className="text-sm text-gray-700">
                          L'IA extraira automatiquement les donn√©es cl√©s de vos documents 
                          (valeurs d'analyses, diagnostics, traitements) pour enrichir votre dossier.
                        </p>
                      </div>
                    </Card>
                  </div>
                </TabsContent>
              </Tabs>
            </Card>
          </div>

          {/* Contextual Chips */}
          <div>
            <Card className="p-6">
              <h3 className="text-gray-900 mb-4">Pr√©cisions rapides</h3>
              <div className="flex flex-wrap gap-2">
                {chips.map((chip) => (
                  <Badge
                    key={chip}
                    variant={selectedChips.includes(chip) ? "default" : "outline"}
                    className={`cursor-pointer transition-colors ${
                      selectedChips.includes(chip) 
                        ? 'bg-blue-600 hover:bg-blue-700' 
                        : 'hover:bg-gray-100'
                    }`}
                    onClick={() => toggleChip(chip)}
                  >
                    {chip}
                    {selectedChips.includes(chip) && (
                      <X className="w-3 h-3 ml-1" />
                    )}
                  </Badge>
                ))}
              </div>
            </Card>

            <Card className="p-6 mt-6 bg-blue-50 border-blue-200">
              <h3 className="text-gray-900 mb-2">üí° Conseil</h3>
              <p className="text-sm text-gray-700">
                Plus vous √™tes pr√©cis dans la description de vos sympt√¥mes, 
                plus l'analyse IA sera pertinente.
              </p>
            </Card>
          </div>
        </div>

        {/* Actions */}
        <div className="flex gap-4 mt-8">
          <Button variant="outline" onClick={() => onNavigate('patient-consent')}>
            Retour
          </Button>
          <Button 
            className="flex-1 bg-blue-600 hover:bg-blue-700"
            onClick={handleAnalyze}
            disabled={saving || uploadingImages || uploadingDocuments || transcribingAudio || recordingAudio}
          >
            {saving ? 'Enregistrement...' : 'Analyser mes sympt√¥mes'}
          </Button>
        </div>
      </div>
    </div>
  );
}

